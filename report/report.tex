\documentclass[danish]{article}

\usepackage{fullpage} 
\usepackage[latin1]{inputenc} 
\usepackage[danish]{babel}
\usepackage{listings} 
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{amssymb} 
\usepackage{amsmath} 
\usepackage{fancyhdr}
\usepackage{lastpage} 
\usepackage{hyperref}
\usepackage{parskip} 
\usepackage{graphicx} 
\usepackage{epstopdf}
\usepackage{abstract}
\usepackage{url}
\usepackage{float}


% setup c sharp syntax highlight 
\lstdefinestyle{sharpc}{ language=[Sharp]C,
frame=lr, rulecolor=\color{black}, basicstyle=\footnotesize\ttfamily,
keywordstyle=\bfseries\color{green!40!black},
commentstyle=\itshape\color{purple!40!black}, identifierstyle=\color{blue},
stringstyle=\color{orange}}

\lstset{ style=sharpc, numbers=left, escapeinside={\<*}{*>},
breakatwhitespace=true }

% code formatting helper 
\newcommand{\code}[1]{\texttt{#1}}

% no paragraph indention 
\setlength{\parindent}{0pt}

% setup page style 
\pagestyle{fancy} 
\fancyhf{} 
\setlength{\headheight}{15pt}
\setlength{\headsep}{25pt} 
\lfoot{Side \thepage{} af 8}
\rfoot{07/05-2013} \lhead{02180 Intro to A.I.} 
\chead{Heureka} 
\rhead{}

\author{
  Patrick Gadd\\
  \texttt{s113491}
  \and
  Simon Altschuler\\
  \texttt{s123563}
}
\title{Heureka projekt}
\date{07/05-2013}

\begin{document}
\maketitle

\textbf{Abstract} \\ 
I denne opgave gennemgås hvordan deduktion i sætningslogik (eng: Propositional Logic) samt rutefinding kan optimeres ved at repræsentere disse som grafer.
Når denne type problemer er repræsenteret som grafer, er det muligt at anvende \code{A*}-algoritmen, med en passende heuristisk funktion, til at finde en løsning mere effektivt end ved eksempelvis Breadth-First-Search (BFS) eller Uniform-Cost-Search (UCS).
I opgaven vil teorien bag samt implementationen blive gennemgået.

\clearpage

\section{Introduktion} 

Til projektet har vi brugt \code{C\#} til implementation af programmet. Vi har gjort brug af \code{LINQ}\footnote{\url{http://en.wikipedia.org/wiki/Language_Integrated_Query}} til data håndtering i mange tilfælde. 

Vi har bestræbt os på at implementere et system der er generisk nok til at håndtere både inferens og rutefinding på hovedsageligt samme vis. Vi har implementeret tests af forskellige edge-cases, eksempelvis et tilfælde i inferens hvor ancestor resolution er nødvendig.

Vi gennemgår først hvordan søgningen foregår teoretisk, og derefter hvor det er implementeret for henholdsvis rutefinding og inferens, og forskellen derimellem.

\section{\code{A*} generelt} 
\code{A*}-algoritmen bruges generelt til at søge mere effektivt i grafer, end \code{BFS} og \code{UCS}, som den tager udgangspunkt i.
Algoritmen forudsætter dog at der er tale om informeret søgning, hvilket betyder at man fra en vilkårlig knude kan estimere hvor langt man er fra mål-knuden i søgningen, samt at der holdes styr på hvor dybt den givne knude ligger i søgetræet.

\code{BFS} prioriterer at man udforsker knuder, sådan at dybden af grenene i søgetræet maksimalt er dybden én fra hinanden.
Dette opnås ved at lægge knuderne i en \code{FIFO-kø}.

\code{UCS} bygger videre på \code{BFS}, men introducerer en cost-funktion, \code{g(n)}, som anvender vægtning af kanterne mellem knuder til at holde søgegrenenes længde uniform.
\code{g(n)} er summen af kantlængderne fra rodknuden til den nuværende.
\code{FIFO-køen} udskiftes med en prioritetskø, der netop bruger \code{g(n)} til at afgøre hvilken knude der skal udforskes som den næste.

\code{A*} er en videreudvikling af \code{UCS}, der anvender en heuristisk-funktion, \code{h(n)}, som forsøger at forudsige hvor langt der højst er til mål-knuden fra en given knude.
Ved at tage summen af \code{g(n)} og \code{h(n)} har man et optimistisk estimat for den totale længde af den korteste rute fra en knude i prioritetskøen, \code{f(n)}.
Hermed forsøger algoritmen direkte at følge den korteste rute til mål-knuden.

Når algoritmen udforsker en knude, vil det i kraft af \code{f(n)}, være den på den korteste rute til mål-knuden gennem den givne knude.
Dette medfører at når en knude én gang har været udforsket, skal andre ruter/grene af søgningen ikke efterfølgende udforske ruter hvori den indgår, da disse vil have større \code{f(n)} i sidste ende.

\subsection{Implementering af algoritmen}
Vi har forsøgt at implementere algoritmen så generisk som muligt, sådan at så længe det man arbejder med kan repræsenteres som en graf med meningsfuld heuristik, bør algoritmen virke.
Et \code{State} svarer til en knude i grafen, hvor en \code{Action} svarer til en kant mellem to knuder. 
En \code{Node}, n, er en knude i det søgetræ der fremkommer ved søgning i grafen, og indeholder information om \code{State}, \code{Action}, \code{Parent} (forgænger i søgetræet) samt \code{g(n)} og \code{h(n)}

Vi har taget udgangspunkt i UCS\footnote{Artificial Intelligence: A modern approach (Russel \& Norvig, 3rd edition) s. 84}
\begin{lstlisting}
SearchResult Search(Node initialNode, KnowledgeBase kb) {  
  frontier = new PriorityQueue<NodeAbstract>();
  explored = new List<StateAbstract>();
  end = initialNode.Target;  //Målet med søgningen
  frontier.Add(initialNode);
  explored.Add(initialNode.State);
\end{lstlisting}
Efter initialisering begynder den iterative søgning:
\begin{lstlisting}[firstnumber=7]  
  while (frontier.Count > 0) {
    currentNode = frontier.Pop(); //elementet forrest i prioritetskøen skal udforskes
    if (currentNode.State.Equals(end)) //Returnerer hvis målet er nået
      return new SearchResult(currentNode, statesSearched, true); 
   	
    actions = kb.ActionsForNode(currentNode);//Handlinger der er relevante for knuden	
  
    foreach (var action in actions) { //Knuden udforskes
      child = kb.Resolve(currentNode, action, end); //Udfør handling
      if (!explored.Contains(child.State)) {
        explored.Add(child.State);
        frontier.Add(child);
      }
\end{lstlisting}
Hvis hverken \code{explored} eller \code{frontier} indeholder \code{child}-knuden bliver denne tilføjet til \code{explored} og \code{frontier}.
Ellers hvis \code{frontier} indeholder en \code{State} lig \code{child.State}, skal der undersøges om \code{child.State} har en lavere \code{PathCost}, og i så fald erstattes. *** uddybende forklaring?
\begin{lstlisting}[firstnumber=20]
      else {
        for (int i = 0; i < frontier.Count; i++) {
          frontierNode = frontier[i];
          if (frontierNode.State.Equals(child.State)
            && frontierNode.PathCost > child.PathCost) {
            frontier[i] = child;
            break;}
        }
      }
    }
  }
  return new SearchResult(null, statesSearched, false);
}

\end{lstlisting}
Hvis ovenstående kontrol undlades, risikeres det at søgningen returnerer en sub-optimal løsning:

\begin{figure}[H]
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.4\linewidth]{simple_optimal.png}
    \caption{Søgningen som den bør foregå}
    \label{src:optimal}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.4\linewidth]{simple_suboptimal.png}
    \caption{Søgningen når den omtalte kontrol undlades}
    \label{src:suboptimal}
  \end{subfigure}
  \label{src:control_loop}
  \caption{Det ses at algoritmen uden kontrol udelukkende arbejder ud fra den estimerede totale omkostning, og ikke får anvendt informationen fra \code{g(n)} om den reelle omkostning}
\end{figure}

\subsubsection{Prioritetskø}
\code{A*} algoritmen gør brug af en såkaldt prioritetskø kaldet \code{frontier} i koden. Denne er implmenteret som en liste der sorterer alle elementerne ved hver indsættelse af et nyt element. Elementerne, som er \code{Node}s, sorteres efter deres totale estimerede cost til mål ($f(n)$), således at \code{Node}n der umiddelbart er mest lovende undersøges først. Dette er ikke den mest optimale måde at implementere en prioritets kø, men det er tilstrækkeligt til dette projekt.

\section{Rutefinding} 
I rutefinding har vi implementeret \code{A*} algoritmen med formålet at finde korteste vej i en vægtet graf, som repræsenterer faktiske kort over landområder.
Vi har testet vores implementation med de fra undervisningen givne kort over dele af København og ``Manhattan'', samt nogle vi selv har konstrueret for at ramme edge-cases.

\subsection{Repræsentation af data / Datastrukturer}
I rutefinding består et \code{State} af et \code{(X,Y)} koordinat som beskriver knudens position på kortet. Dette er alt hvad der skal bruges for at udregne den heuristiske værdi fra en arbitrær knude til en given mål-\code{State}.

En \code{Action} finder sin cost ved at udregne afstanden mellem sit \code{StartState} og \code{EndState}s koordinater.

Knowledge basen (KB) for rutefinding genereres ud fra en tekstfil med følgende struktur:

\begin{verbatim}
startX_1 startY_1 navn_1 slutX_1 slutY_1
startX_2 startY_2 navn_2 slutX_2 slutY_2
...
startX_n startY_n navn_n slutX_n slutY_n
\end{verbatim}

Dette bliver parset til to states (start og end) og en action i mellem dem, som alle bliver gemt i KB'en. Alle \code{Action}s bliver fundet på forhånd så \code{A*} algoritmen ikke skal søge gennem \code{State}s under eksekvering, men blot kan slå de relevante \code{Action}s op. Det betyder et større pladsforbrug, og længere tid til parsing, men en bedre tidskompleksitet mht. selve søgningen.

Hver linie i KB'en repræsenterer en \emph{ensrettet} vej, hvilket vil sige at der skal to linier til at beskrive en vej på hvilken man både kan gå den ene og den anden vej.


\subsection{Heuristik}
Den heuristiske værdi, \code{h(n)}, for en \code{Node}, n, i rutefinding er bestemt ud fra fugleflugts afstanden til målet.
Den strategi egner sig bedst til grafer med få ``blindgyder'', da \code{h(n)} ikke kan tage højde for disse og vil forsøge at gå ned af blindgyderne hvis de geografisk ligger tættere på målet.

\code{f(n)}, den samlede estimerede omkostning (cost indtil nu plus estimeret afstand til mål), udregnes på følgende måde for enhver knude i grafen under rutefinding:
\[ h(n) = \sqrt{(n.State.X - TargetState.X)^2 + (n.State.Y - TargetState.Y)^2} \]
\[ g(n) = n.PathCost = n.Parent.PathCost + n.Action.Cost \]
\[ f(n) = g(n) + h(n) \]
Hvor \code{n.Parent} er den \code{Node} fra hvilken søgningen kom til den nuværende \code{Node}.

\code{n.PathCost} er den faktiske omkostning for at komme til \code{Node}n fra startpunktet.
Det bemærkes at en \code{Node} har både en \code{Action} (som er den \code{Action} der blev taget for at komme til \code{Node}n) og et \code{State}, som skal bruges til at udregne den samlede cost (\code{PathCost}).

\subsection{Setup og kørsel af programmet}
Kørsel af en rutefinding foregår ved først at parse en tekstfil til en KB. Den KB, sammen med et \code{StartState} og \code{EndState} gives som parametre til \code{AStar.Search()}, som returnerer et \code{SearchResult}. \code{SearchResult} indeholder den funde mål-\code{Node}, hvis der findes en sti dertil.
Denne \code{Node} er første element i en linked list af \code{Node}s som fører tilbage til knuden der blev søgt fra ved hjælp af deres \code{Parent}-egenskab. På den måde kan hele ruten printes/analyseres. 

Vi har udvidet vores program med kode til at tegne en given rute-graf og den fundne rute mellem to knuder. På figuren nedenfor ses hvordan programmet visualiserer en rute gennem København-grafen:

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.65]{copenhagen.png}
  \label{scr:copenhagen}
  \caption{Ruten (markeret med grønt) fra start (blå) til slut (rød). Det bemærkes at de fleste veje er ensrettede og ruten derfor ikke tager den umiddelbart intuitive form. Det ér dog den optimale rute der er fundet og markeret.}
\end{figure}

\section{Inferens} 
Inferens delen af koden er på de fleste områder meget lig rutefindingen. Vi har gjort koden generisk nok til at de begge benytter den samme \code{A*} implementation, og at begge slags KB implementerer et fælles interface.

Ydermere extender \code{Node}, \code{Action} og \code{State} i både inferens og rutefinding fra de abstrakte implementationer, hvilket bl.a. er det der muliggør den ensartede \code{A*} søgning.

De største forskelle ligger i udregning af den heuristiske værdi, og hvad et \code{State} består af, samt hvad målet er. 

I inferens søgningen/deduktionen udføres beviset ved hjælp af modstrid: Man negerer det \code{StartState} man ønsker at bevise (f.eks. $\lnot water$ hvis man ønsker at bevise $water$), og går således efter den tomme klausul. Det gør man fordi det vil betyde at den opstillede KB ikke er konsistent, hvis det indførte udsagn er sandt.

\subsection{Repræsentation af data / Datastrukturer}
I inferens består et \code{State} af en liste af \code{Literal}s, kaldet en klausul. En \code{Literal} er en atomar konstant der enten er positiv eller negativ. Det kan f.eks. være $water$ som ville betyde at konstanten ``water'' gælder, hvorimod $\lnot water$ ville betyde at ``water'' \emph{ikke} gælder.

En liste af disse kalder vi som sagt klausuler, og det er disse der udgør et \code{State} i inferens søgning. KB'en er i CNF\footnote{Artificial Intelligence: A modern approach (Russel \& Norvig, 1st edition), s. 278} format, hvilket vil sige at den er opstillet af et antal konjunkerede klausuler bestående af literaler.

Matematisk set har KB'en formattet:
\[
(P_1 \lor P_2 ... \lor P_n) \land (Q_1 \lor Q_2 ... \lor Q_n) ...
\]
Hvor paranteserne indeholder en klausul og det hele er en KB i CNF format. Ligesom i rutefinding bliver inferens KB'erne parset ud fra en tekstfil med følgende format
\begin{verbatim}
-literal_1 literal_2
-literal_2 literal_3
literal_4 literal_1 literal_3
\end{verbatim}
Her betyder ``-'' negering af literalet. Hver linie i filen svarer til en klausul af disjunkerede literaler, så mellemrum mellem literalerne er altså et implicit $\lor$.

\subsubsection{Opstilling af en CNF KB}
Når en KB skal opstilles i CNF format skal der sædvanligvis omskrives fra udsagnslogisk format til disjunkerede klausuler. Det har vi gjort ved at benytte regler som f.eks. De Morgans lov\footnote{Artificial Intelligence: A modern approach (Russel \& Norvig, 1st edition), s. 193}, og generelle omskrivningsregler\footnote{AI Lore 9 side 7 samt Artificial Intelligence: A modern approach (Russel \& Norvig, 1st edition) s. 281}. Eksempelvis gælder følgende omskrivning fra udsagnslogik til disjunkeret literaler:
\[
vand \land sol \to liv
\equiv \lnot(vand \land sol) \lor liv
\equiv \lnot vand \lor \lnot sol \lor liv
\]
Som ville være en linie i en KB-tekstfilen således: 
\begin{verbatim}
-vand -sol liv
\end{verbatim}

\subsection{Resolution}
Når metoden Resolve(\code{Node}, \code{Action}) bliver kaldet i inferens-delen, bliver der udført resolution af to klausuler. Det har vi implementeret på følgende måde: *** uddybning?
\begin{lstlisting}[mathescape]
foreach (var firstLiteral in parent.State.Clause) {
  foreach (var secondLiteral in action.Clause) {
    if (firstLiteral.Name.Equals(secondLiteral.Name)
      && firstLiteral.Proposition != secondLiteral.Proposition) {
      // Merger samtlige literals fra de to clauses
      // f.eks. $ (A \lor \lnot B) \land (A \lor B) $ -> $A \lor \lnot B \lor A \lor B $
      state.Clause = parent.State.Clause.Concat(action.Clause).ToList();

      // Fjern en enkelt positiv og en enkelt negativ af de literals med samme navn
      // f.eks. $A \lor \lnot B \lor A \lor B $ -> $A \lor A $
      state.Clause.Remove(state.Clause.First(lit => lit.Name.Equals(secondLiteral.Name)
        && lit.Proposition));
      state.Clause.Remove(state.Clause.First(lit => lit.Name.Equals(secondLiteral.Name)
        && !lit.Proposition));

      // Fjerner duplikater, f.eks. $A \lor A $ -> $A $
      state.Clause = state.Clause.Distinct().ToList();

      return new InferenceNode(parent, parent.Target, state, 
        new InferenceAction(state, parent.Target));
}}}\end{lstlisting}

\subsection{Heuristik}
Den heuristiske værdi i inferens er simpelthen lig med antallet af literaler i en klausul. Det er den fordi målet altid er den tomme klausul, dvs. indeholdende nul literaler, da vi benytter indirekte bevisførelse.
Dermed bliver den estimerede totale længde af søgningen \code{f(n)}:
\[ h(n) = this.State.Clause.Count \]
\[ g(n) = n.PathCost = n.Parent.PathCost + 1\]
\[ f(n) = g(n) + h(n) \]

I inferens-delen af programmet, har vi valgt kun at anvende \code{h(n)} som den værdi der sorteres efter i \code{Frontier} af to grunde:
\begin{itemize}
\item KB'en $(P \lor \lnot Q) , (\lnot P \lor Q) , (P \lor Q) , (\lnot P \lor \lnot Q)$, kan kun vises at være inkonsistent hvis vi udelukkende anvender \code{h(n)}
\item Samtlige af de KB'er vi har implementeret tests for bliver løst ved højst lige så mange iterationer når der udelukkende anvendes \code{h(n)}. Eksempelvis bliver Espresso KB'en\footnote{\url{http://www.cs.toronto.edu/~sheila/2542/w06/readings/ijcai_pblr.pdf} slide 34} løst ved 20 iterationer når h(n) anvendes, mens der bruges 671 iterationer på at løse den, når \code{Frontier} sorteres efter f(n).
\end{itemize}

Ved at gøre dette er man ikke nødvendigvis sikker på at den optimale løsning nås, men i inferens formoder vi at det er vigtigere at kunne svare på hvorvidt et statement er sandt eller ej, fremfor \emph{hvordan} man kommer til den konklusion.

\subsection{Setup og kørsel af programmet}
Kørsel af en inferens søgning foregår på næsten identisk vis som i rutefinding. Der parses en tekstfil til en KB. Denne, og et start- og mål-\code{State}, gives som parametre til \code{AStar.Search()} funktionen. På samme måde som rutefinding fås naturligvis også et resultat tilbage i form af et \code{SearchResult}

\section{Konklusion} 
Vi har succesfuldt implementeret både rutefinding og inferens maskinen, som bruger samme søgemoduler og deler mange egenskaber. Der er plads til forbedring, specielt hvad angår performance.

Vi har formået at lave et brugbart program og teste det i mange henseender. Ydermere har vi visualiseret rutefindingen, både for at verificere de forskellige KB'er, og for at få en bedre indsigt i hvordan vores søgealgoritme går til værks.

\subsection{Output}
Outputtet er ikke af nogen særlig interesse, med undtagelse af hvor mange iterationer der blev brugt til at finde løsningen. Følgende er outputtet af nogle tests
\begin{verbatim}
--- Inference ---
Test: Simple failure: SUCCESS (not solved in 1 iteration)
Test: Breakfast: SUCCESS (solved in 10 iterations)
Test: Ancestor (pq): SUCCESS (solved in 5 iterations)
Test: Espresso light: SUCCESS (solved in 7 iterations)
Test: No steam (boiler broken): SUCCESS (solved in 3 iterations)
Test: Espresso: SUCCESS (solved in 20 iterations)
Passed 6 of 6 (100%)

--- Route finding ---
Test: Manhattan ... Parsing ... Solving: SUCCESS (solved in 58 iterations)
Test: Copenhagen ... Parsing ... Solving: SUCCESS (solved in 14 iterations)
Test: Simple Copenhagen ... Parsing ... Solving: SUCCESS (solved in 8 iterations)
Test: Manhattan with diagonals ... Parsing ... Solving: SUCCESS (solved in 30 iterations)
Test: Big Manhattan ... Parsing ... Solving: SUCCESS (solved in 894 iterations)
Passed 5 of 5 (100%)
\end{verbatim}

\subsection{Status på engine}
Der er stadigvæk to problemer med vores Heureka-program:
\begin{itemize}
\item Rutefindingen er ineffektiv ved ruter med mange optimale løsninger, hvilket ses ud fra ovenstående udskrift af testene: "Manhattan with diagonals" er et 30x30 kort, med diagonaler og "Big Manhattan" er et 30x30 kort, uden diagonaler. Begge tests går fra et hjørne diagonalt til det modsatte.
\item Når der resolves i inferens-delen tages der ikke højde for at der kan komme flere end én ny klausul. Eksempelvis vil $Resolve((p \lor q),(\lnot p \lor \lnot q)) $ kun returnere enten $(p \lor \lnot p)$ eller $(q \lor \lnot q)$, selvom den bør returnere begge. Dette har vi ikke fået implementeret, og det kan være en mulig forklaring på at KB'en beskrevet i afsnit 4.3 ikke virker i nogle tilfælde.
\end{itemize}

Mangler at implementere at én resolve kan give flere Nodes.

\subsubsection{Datastrukturer}
Vi har i implementeringen ikke primært fokuseret på optimering, dog vil vi gerne nævne to oplagte muligheder for det:

1) \code{Frontier} er en prioritetskø implementeret med en List, som vi sorterer ved indsættelse af \code{Nodes} i denne.
Jf. Microsofts dokumentation\footnote{\url{http://msdn.microsoft.com/en-us/library/b0zbh7b6.aspx}} anvendes Quicksort ved sortering af en List.
Best-case køretiden for denne metode er O( n * log(n) ), hvilket vi antager må være køretiden da \code{Frontier} altid er sorteret pånær højst ét element - det senest indsatte.
Havde vi implementeret \code{Frontier} med en binær Min-Hob, havde køretiden for indsættelse blot været log(n).
Derudover er der også fordele mht. køretid for Min-Hob ved søgning, da List anvender lineær søgning og ikke binær, og \code{A*} for hver iteration søger \code{Frontier} igennem.

Derfor er det oplagt at anvende en binær Min-Hob i \code{Frontier}, hvis man ønsker at optimere.

2) \code{Explored} bliver også gennemsøgt flere gange for hver iteration, og bliver hurtigt meget stor, hvorfor en effektiv søgning er ønskelig.
Også til \code{Explored} har vi anvendt en List, hvor søgning efter matchende elementer har en køretid på O(n).
I dette tilfælde er det oplagt at anvende et HashSet, da gennemsøgning er det primære \code{Explored} anvendes til, og søgning efter et specifikt element i et HashSet har en forventet køretid på O(1).

\end{document}